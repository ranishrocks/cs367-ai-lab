{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMPuEg+ZsKGqORzfrUeLKej",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ranishrocks/cs367-ai-lab/blob/main/lab%202/%20plag.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HCYTxzwWcs4b"
      },
      "outputs": [],
      "source": [
        "import heapq\n",
        "import string\n",
        "import numpy as np\n",
        "import re\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def preprocess_text(doc):\n",
        "    sentences = doc.split('.')\n",
        "    return [s.strip().lower() for s in sentences if s.strip()]\n",
        "\n",
        "def calculate_cosine_similarity(doc1_sentences, doc2_sentences):\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    all_sentences = doc1_sentences + doc2_sentences\n",
        "    tfidf_matrix = vectorizer.fit_transform(all_sentences)\n",
        "\n",
        "    similarities = cosine_similarity(tfidf_matrix[:len(doc1_sentences)], tfidf_matrix[len(doc1_sentences):])\n",
        "    return similarities\n"
      ],
      "metadata": {
        "id": "ZD7-IWkbdDTL"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def levenshtein_distance(s1, s2):\n",
        "    m, n = len(s1), len(s2)\n",
        "    dp = np.zeros((m + 1, n + 1))\n",
        "    for i in range(m + 1):\n",
        "        for j in range(n + 1):\n",
        "            if i == 0:\n",
        "                dp[i][j] = j\n",
        "            elif j == 0:\n",
        "                dp[i][j] = i\n",
        "            elif s1[i-1] == s2[j-1]:\n",
        "                dp[i][j] = dp[i-1][j-1]\n",
        "            else:\n",
        "                dp[i][j] = 1 + min(dp[i-1][j], dp[i][j-1], dp[i-1][j-1])\n",
        "    return dp[m][n]\n"
      ],
      "metadata": {
        "id": "yhb43ukbdF44"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def heuristic(doc1_sentences, doc2_sentences, index1, index2):\n",
        "    # Estimate based on the difference in remaining sentences\n",
        "    remaining1 = len(doc1_sentences) - index1\n",
        "    remaining2 = len(doc2_sentences) - index2\n",
        "    return abs(remaining1 - remaining2)\n"
      ],
      "metadata": {
        "id": "Qjzx1drhdISf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def a_star_search(doc1_sentences, doc2_sentences):\n",
        "    start_state = (0, 0, 0)  # (index in doc1, index in doc2, current cost)\n",
        "    frontier = [(0, start_state)]  # Priority queue (cost, state)\n",
        "    explored = set()\n",
        "\n",
        "    # Store the alignment results\n",
        "    alignments = []\n",
        "\n",
        "    while frontier:\n",
        "        cost, (i, j, current_cost) = heapq.heappop(frontier)\n",
        "\n",
        "        if (i, j) in explored:\n",
        "            continue\n",
        "\n",
        "        explored.add((i, j))\n",
        "\n",
        "        # Goal: all sentences from both documents are aligned\n",
        "        if i == len(doc1_sentences) and j == len(doc2_sentences):\n",
        "            return alignments\n",
        "\n",
        "        # Align sentence i with sentence j\n",
        "        if i < len(doc1_sentences) and j < len(doc2_sentences):\n",
        "            align_cost = levenshtein_distance(doc1_sentences[i], doc2_sentences[j])\n",
        "            next_cost = current_cost + align_cost\n",
        "            heapq.heappush(frontier, (next_cost + heuristic(doc1_sentences, doc2_sentences, i+1, j+1),\n",
        "                                      (i+1, j+1, next_cost)))\n",
        "            alignments.append((i, j, align_cost))  # Save alignment information\n",
        "\n",
        "        # Skip a sentence in doc1\n",
        "        if i < len(doc1_sentences):\n",
        "            skip_cost_doc1 = current_cost + len(doc1_sentences[i])  # Cost of skipping\n",
        "            heapq.heappush(frontier, (skip_cost_doc1 + heuristic(doc1_sentences, doc2_sentences, i+1, j),\n",
        "                                      (i+1, j, skip_cost_doc1)))\n",
        "\n",
        "        # Skip a sentence in doc2\n",
        "        if j < len(doc2_sentences):\n",
        "            skip_cost_doc2 = current_cost + len(doc2_sentences[j])  # Cost of skipping\n",
        "            heapq.heappush(frontier, (skip_cost_doc2 + heuristic(doc1_sentences, doc2_sentences, i, j+1),\n",
        "                                      (i, j+1, skip_cost_doc2)))\n",
        "\n",
        "    return alignments  # Return empty if no alignment found\n"
      ],
      "metadata": {
        "id": "zRyP-fSUdKz4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_plagiarism_cosine(doc1_sentences, doc2_sentences, threshold=0.3):\n",
        "    plagiarism_cases = []\n",
        "    similarities = calculate_cosine_similarity(doc1_sentences, doc2_sentences)\n",
        "\n",
        "    for i in range(len(doc1_sentences)):\n",
        "        for j in range(len(doc2_sentences)):\n",
        "            if similarities[i, j] >= threshold:\n",
        "                plagiarism_cases.append((doc1_sentences[i], doc2_sentences[j], similarities[i, j]))\n",
        "\n",
        "    return plagiarism_cases\n"
      ],
      "metadata": {
        "id": "rOhboMybdN_5"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Case 1: Identical Documents\n",
        "doc1 = \"\"\"Climate change is one of the most pressing issues of our time.\"\"\"\n",
        "doc2 = \"\"\"Climate change is one of the most pressing issues of our time.\"\"\"\n",
        "\n",
        "# Preprocess both documents\n",
        "doc1_sentences = preprocess_text(doc1)\n",
        "doc2_sentences = preprocess_text(doc2)\n",
        "\n",
        "# Run A* search to align sentences\n",
        "alignments = a_star_search(doc1_sentences, doc2_sentences)\n",
        "\n",
        "# Detect potential plagiarism\n",
        "plagiarism_cases = detect_plagiarism(alignments, doc1_sentences, doc2_sentences, threshold=1)\n",
        "\n",
        "# Output for Test Case 1\n",
        "print(\"Test Case 1: Identical Documents\")\n",
        "if plagiarism_cases:\n",
        "    for sentence1, sentence2, cost in plagiarism_cases:\n",
        "        print(f\"Aligned Sentence 1: {sentence1}\")\n",
        "        print(f\"Aligned Sentence 2: {sentence2}\")\n",
        "        print(f\"Edit Distance: {cost}\\n\")\n",
        "else:\n",
        "    print(\"No potential plagiarism detected.\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLQLFjXzdPit",
        "outputId": "9f1d095f-d6da-496d-f7fd-bf69df32e2d6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Case 1: Identical Documents\n",
            "Aligned Sentence 1: climate change is one of the most pressing issues of our time\n",
            "Aligned Sentence 2: climate change is one of the most pressing issues of our time\n",
            "Edit Distance: 0.0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Case 2: Slightly Modified Document\n",
        "doc1 = \"\"\"Climate change poses a serious threat to the planet.\"\"\"\n",
        "doc2 = \"\"\"Global warming presents a significant risk to Earth.\"\"\"\n",
        "\n",
        "# Preprocess both documents\n",
        "doc1_sentences = preprocess_text(doc1)\n",
        "doc2_sentences = preprocess_text(doc2)\n",
        "\n",
        "# Run A* search to align sentences\n",
        "alignments = a_star_search(doc1_sentences, doc2_sentences)\n",
        "\n",
        "# Detect potential plagiarism\n",
        "plagiarism_cases = detect_plagiarism(alignments, doc1_sentences, doc2_sentences, threshold=5)\n",
        "\n",
        "# Output for Test Case 2\n",
        "print(\"Test Case 2: Slightly Modified Document\")\n",
        "if plagiarism_cases:\n",
        "    for sentence1, sentence2, cost in plagiarism_cases:\n",
        "        print(f\"Aligned Sentence 1: {sentence1}\")\n",
        "        print(f\"Aligned Sentence 2: {sentence2}\")\n",
        "        print(f\"Edit Distance: {cost}\\n\")\n",
        "else:\n",
        "    # Show aligned sentences with their costs even if no potential plagiarism is detected\n",
        "    print(\"No potential plagiarism detected. Here are the alignments with edit distances:\")\n",
        "    for i, j, cost in alignments:\n",
        "        print(f\"Alignment between Document 1 Sentence {i} and Document 2 Sentence {j}: Edit Distance: {cost}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZA1fIazmdhHC",
        "outputId": "de445d9d-1d53-4869-bff1-1f3e3e6fea6f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Case 2: Slightly Modified Document\n",
            "No potential plagiarism detected. Here are the alignments with edit distances:\n",
            "Alignment between Document 1 Sentence 0 and Document 2 Sentence 0: Edit Distance: 35.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Case 3: Completely Different Sentences\n",
        "doc1 = \"\"\"The moon shines brightly in the night sky.\"\"\"\n",
        "doc2 = \"\"\"Photosynthesis is essential for plant growth.\"\"\"\n",
        "\n",
        "# Preprocess both documents\n",
        "doc1_sentences = preprocess_text(doc1)\n",
        "doc2_sentences = preprocess_text(doc2)\n",
        "\n",
        "# Run A* search to align sentences\n",
        "alignments = a_star_search(doc1_sentences, doc2_sentences)\n",
        "\n",
        "# Detect potential plagiarism\n",
        "plagiarism_cases = detect_plagiarism(alignments, doc1_sentences, doc2_sentences, threshold=5)\n",
        "\n",
        "# Output for Test Case 3\n",
        "print(\"Test Case 3: Completely Different Sentences\")\n",
        "if plagiarism_cases:\n",
        "    for sentence1, sentence2, cost in plagiarism_cases:\n",
        "        print(f\"Aligned Sentence 1: {sentence1}\")\n",
        "        print(f\"Aligned Sentence 2: {sentence2}\")\n",
        "        print(f\"Edit Distance: {cost}\\n\")\n",
        "else:\n",
        "    print(\"No potential plagiarism detected.\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lI1L5w7eD8V",
        "outputId": "ac3c4220-2d9c-4faf-d4c9-a915e013134f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Case 3: Completely Different Sentences\n",
            "No potential plagiarism detected.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc1 = \"\"\"Artificial Intelligence can improve efficiency in various tasks.\"\"\"\n",
        "doc2 = \"\"\"AI technology has the potential to enhance productivity in many areas.\"\"\"\n",
        "\n",
        "# Preprocess both documents\n",
        "doc1_sentences = preprocess_text(doc1)\n",
        "doc2_sentences = preprocess_text(doc2)\n",
        "\n",
        "# Detect potential plagiarism using cosine similarity\n",
        "plagiarism_cases = detect_plagiarism_cosine(doc1_sentences, doc2_sentences, threshold=0.3)\n",
        "\n",
        "# Output for Test Case 4\n",
        "print(\"Test Case 4: Partial Overlap\")\n",
        "if plagiarism_cases:\n",
        "    for sentence1, sentence2, sim in plagiarism_cases:\n",
        "        print(f\"Aligned Sentence 1: {sentence1}\")\n",
        "        print(f\"Aligned Sentence 2: {sentence2}\")\n",
        "        print(f\"Cosine Similarity: {sim}\\n\")\n",
        "else:\n",
        "    print(\"No potential plagiarism detected.\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHlTACsjeMZf",
        "outputId": "7d2c6600-a52d-4fef-ef8f-71cd0d66f232"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Case 4: Partial Overlap\n",
            "No potential plagiarism detected.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}